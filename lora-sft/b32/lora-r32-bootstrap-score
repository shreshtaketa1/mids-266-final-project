{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaWdKzngG231","executionInfo":{"status":"ok","timestamp":1753355273379,"user_tz":360,"elapsed":436,"user":{"displayName":"Erica Irwin Landreth","userId":"17078375249090773275"}},"outputId":"31fc78f4-b35b-41f5-f198-eb388994067a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# mount Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install -q -U datasets transformers"],"metadata":{"id":"Qws03rvGHJmE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prep dataset"],"metadata":{"id":"Vu-yQ4ROHNLj"}},{"cell_type":"code","source":["# prepare data\n","from datasets import load_dataset\n","eval_dataset = load_dataset(\"FreedomIntelligence/medical-o1-verifiable-problem\", split=\"train[:1%]\")"],"metadata":{"id":"XzlgwPgTHMeb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","eval_dataset = pd.DataFrame(eval_dataset)\n","eval_dataset.head()"],"metadata":{"id":"iF_blsNzHU-w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Read in model output"],"metadata":{"id":"MpVN44X0HgqJ"}},{"cell_type":"code","source":["fn_out = \"/content/drive/MyDrive/266 Final Project/model_output/lora-sft-r32-output-reformatted-bootstrap-output.txt\"\n","f = open(fn_out, 'r')"],"metadata":{"id":"hHJhNF2mHjM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L = f.readlines()"],"metadata":{"id":"lB4wSCI3Ve91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L[-1]"],"metadata":{"id":"5dfMpdg_qpKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_idx = int(L[-1].split(\"*****!!!!!\")[0])\n","max_idx"],"metadata":{"id":"9eOyOgRCtBxz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prep DeBERTa Model"],"metadata":{"id":"62nTDI3OJE7c"}},{"cell_type":"code","source":["# set up scoring pipeline\n","from transformers import pipeline\n","model_id = \"microsoft/deberta-large-mnli\"\n","pipe = pipeline(\"text-classification\",\n","                model=model_id,\n","                return_all_scores=True)"],"metadata":{"id":"az7jEv7GH0xA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","# forward entailment\n","entF = np.zeros([max_idx+1,5])\n","neuF = np.zeros([max_idx+1,5])\n","negF = np.zeros([max_idx+1,5])\n","# backward entailment\n","entB = np.zeros([max_idx+1,5])\n","neuB = np.zeros([max_idx+1,5])\n","negB = np.zeros([max_idx+1,5])\n","# bag of words scoring\n","bow = np.zeros([max_idx+1,5])\n","# self scoring\n","slf = np.zeros([max_idx+1,5])"],"metadata":{"id":"Id3aO2mItZ0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnt = dict()\n","for i,l in enumerate(L):\n","\n","  print(f\"Processing line {i}\")\n","\n","  proc = l.split('*****!!!!!')\n","  if len(proc) < 2:\n","    continue\n","\n","  # get ground truth\n","  idx = int(proc[0])\n","  print(f\"Dataset index {idx}\")\n","  if idx in cnt.keys():\n","    cnt[idx] += 1\n","  else:\n","    cnt[idx]  = 0\n","\n","  truth = eval_dataset['Ground-True Answer'][idx]\n","\n","  # get DeBERTa containment scores\n","  prompt = f\"[CLS] {truth} [SEP] {proc[1]} [SEP]\"\n","  outputs = pipe(prompt)\n","  negF[idx,cnt[idx]] = outputs[0][0]['score']\n","  neuF[idx,cnt[idx]] = outputs[0][1]['score']\n","  entF[idx,cnt[idx]] = outputs[0][2]['score']\n","  prompt = f\"[CLS] {proc[1]} [SEP] {truth} [SEP]\"\n","  outputs = pipe(prompt)\n","  negB[idx,cnt[idx]] = outputs[0][0]['score']\n","  neuB[idx,cnt[idx]] = outputs[0][1]['score']\n","  entB[idx,cnt[idx]] = outputs[0][2]['score']\n","\n","  # get bag of words containment score\n","  wrds = [w in proc[1].lower() for w in truth.split()]\n","  bow[idx,cnt[idx]] = np.mean(wrds)\n","\n","  # correct/incorrect/don't know processing\n","  rating = proc[1].split(\"\\t\")[-1]\n","  if \"don't know\" in rating.lower():\n","    slf[idx,cnt[idx]] = 0.5\n","  elif \"incorrect\" in rating.lower():\n","    slf[idx,cnt[idx]] = 0\n","  elif \"correct\" in rating.lower():\n","    slf[idx,cnt[idx]] = 1\n","  elif \"don't know\" in proc[1].lower():\n","    slf[idx,cnt[idx]] = 0.5\n","  elif \"incorrect\" in proc[1].lower():\n","    slf[idx,cnt[idx]] = 0\n","  elif \"correct\" in proc[1].lower():\n","    slf[idx,cnt[idx]] = 1\n","  else:\n","    slf[idx,cnt[idx]] = 0.5"],"metadata":{"id":"X_gsEsO8aMeI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","data = {'entF': entF, 'neuF': neuF, 'negF': negF,\n","        'entB': entB, 'neuB': neuB, 'negB': negB,\n","        'bow': bow, 'slf': slf}\n","fn_pkl = fn_out.replace(\".txt\", \".pkl\")\n","with open(fn_pkl, 'wb') as f:\n","    pickle.dump(data, f)"],"metadata":{"id":"yd5QzFeZx7-Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Scoring to prepare bootstrapping data"],"metadata":{"id":"6bG4bKlT9wk3"}},{"cell_type":"code","source":["fn_out = \"/content/drive/MyDrive/266 Final Project/model_output/lora-sft-r32-output-reformatted-bootstrapping.txt\"\n","f = open(fn_out, 'r')"],"metadata":{"id":"Ow3n2wlT315Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L = f.readlines()"],"metadata":{"id":"0p4SEWpH99x5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_idx = int(L[1].split(\"*****!!!!!\")[0])\n","min_idx"],"metadata":{"id":"qtMNXOgP-DeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_idx = int(L[-1].split(\"*****!!!!!\")[0])\n","max_idx"],"metadata":{"id":"88_U8EFE-BTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","# forward entailment\n","entF = np.zeros([max_idx-min_idx+1,5])\n","neuF = np.zeros([max_idx-min_idx+1,5])\n","negF = np.zeros([max_idx-min_idx+1,5])\n","# backward entailment\n","entB = np.zeros([max_idx-min_idx+1,5])\n","neuB = np.zeros([max_idx-min_idx+1,5])\n","negB = np.zeros([max_idx-min_idx+1,5])\n","# bag of words scoring\n","bow = np.zeros([max_idx-min_idx+1,5])\n","# self scoring\n","slf = np.zeros([max_idx-min_idx+1,5])"],"metadata":{"id":"-JNVMSeg-Jsq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnt = dict()\n","for i,l in enumerate(L):\n","\n","  print(f\"Processing line {i}\")\n","\n","  proc = l.split('*****!!!!!')\n","  if len(proc) < 2:\n","    continue\n","\n","  # get ground truth\n","  idx = int(proc[0])\n","  print(f\"Dataset index {idx}\")\n","  if idx in cnt.keys():\n","    cnt[idx] += 1\n","  else:\n","    cnt[idx]  = 0\n","\n","  truth = eval_dataset['Ground-True Answer'][idx]\n","\n","  # get DeBERTa containment scores\n","  prompt = f\"[CLS] {truth} [SEP] {proc[1]} [SEP]\"\n","  outputs = pipe(prompt)\n","  negF[idx-min_idx,cnt[idx]] = outputs[0][0]['score']\n","  neuF[idx-min_idx,cnt[idx]] = outputs[0][1]['score']\n","  entF[idx-min_idx,cnt[idx]] = outputs[0][2]['score']\n","  prompt = f\"[CLS] {proc[1]} [SEP] {truth} [SEP]\"\n","  outputs = pipe(prompt)\n","  negB[idx-min_idx,cnt[idx]] = outputs[0][0]['score']\n","  neuB[idx-min_idx,cnt[idx]] = outputs[0][1]['score']\n","  entB[idx-min_idx,cnt[idx]] = outputs[0][2]['score']\n","\n","  # get bag of words containment score\n","  wrds = [w in proc[1].lower() for w in truth.split()]\n","  bow[idx-min_idx,cnt[idx]] = np.mean(wrds)\n","\n","  # correct/incorrect/don't know processing\n","  rating = proc[1].split(\"\\t\")[-1]\n","  if \"don't know\" in rating.lower():\n","    slf[idx-min_idx-min_idx,cnt[idx]] = 0.5\n","  elif \"incorrect\" in rating.lower():\n","    slf[idx-min_idx,cnt[idx]] = 0\n","  elif \"correct\" in rating.lower():\n","    slf[idx-min_idx,cnt[idx]] = 1\n","  elif \"don't know\" in proc[1].lower():\n","    slf[idx-min_idx,cnt[idx]] = 0.5\n","  elif \"incorrect\" in proc[1].lower():\n","    slf[idx-min_idx,cnt[idx]] = 0\n","  elif \"correct\" in proc[1].lower():\n","    slf[idx-min_idx,cnt[idx]] = 1\n","  else:\n","    slf[idx-min_idx,cnt[idx]] = 0.5"],"metadata":{"id":"Df2bbLYQ-Lww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","data = {'entF': entF, 'neuF': neuF, 'negF': negF,\n","        'entB': entB, 'neuB': neuB, 'negB': negB,\n","        'bow': bow, 'slf': slf}\n","fn_pkl = fn_out.replace(\".txt\", \".pkl\")\n","with open(fn_pkl, 'wb') as f:\n","    pickle.dump(data, f)"],"metadata":{"id":"A2cks9f_-OT6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qjjoYS65MTt0"},"execution_count":null,"outputs":[]}]}