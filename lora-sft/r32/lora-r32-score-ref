{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YaWdKzngG231","executionInfo":{"status":"ok","timestamp":1753846386752,"user_tz":360,"elapsed":26554,"user":{"displayName":"Erica Irwin Landreth","userId":"17078375249090773275"}},"outputId":"2e2d54c2-1ea5-4d96-efce-69d8434ba66e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install -q -U datasets transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qws03rvGHJmE","outputId":"a8fbdca4-21bc-47b5-b8b5-3142327ce4d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["## Prep reference responses dataset"],"metadata":{"id":"Vu-yQ4ROHNLj"}},{"cell_type":"code","source":["fn_out = \"/content/drive/MyDrive/266 Final Project/model_output/lora-sft-r32-output-reformatted-reference.txt\"\n","f = open(fn_out, 'r')\n","ref = f.readlines()\n","ref = [r for r in ref if r != '\\n']\n","ref = [r.split(\"*****!!!!!\")[1] for r in ref]"],"metadata":{"id":"XzlgwPgTHMeb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Read in model output"],"metadata":{"id":"MpVN44X0HgqJ"}},{"cell_type":"code","source":["fn_out = \"/content/drive/MyDrive/266 Final Project/model_output/lora-sft-r32-output-reformatted.txt\"\n","f = open(fn_out, 'r')"],"metadata":{"id":"hHJhNF2mHjM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L = f.readlines()"],"metadata":{"id":"lB4wSCI3Ve91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L[-1]"],"metadata":{"id":"5dfMpdg_qpKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L = [l for l in L if l != '\\n']\n","r = [l.split('*****!!!!!')[1] for l in L]\n","n = [int(l.split('*****!!!!!')[0]) for l in L]\n"],"metadata":{"id":"PF7y-BFkBmUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_idx = max(n)\n","max_idx"],"metadata":{"id":"9eOyOgRCtBxz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prep DeBERTa Model"],"metadata":{"id":"62nTDI3OJE7c"}},{"cell_type":"code","source":["# set up scoring pipeline\n","from transformers import pipeline\n","model_id = \"microsoft/deberta-large-mnli\"\n","pipe = pipeline(\"text-classification\",\n","                model=model_id,\n","                return_all_scores=True)"],"metadata":{"id":"az7jEv7GH0xA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","# forward entailment\n","entF = np.zeros([max_idx+1,5])\n","neuF = np.zeros([max_idx+1,5])\n","negF = np.zeros([max_idx+1,5])\n","# backward entailment\n","entB = np.zeros([max_idx+1,5])\n","neuB = np.zeros([max_idx+1,5])\n","negB = np.zeros([max_idx+1,5])\n","# self scoring\n","slf = np.zeros([max_idx+1,5])"],"metadata":{"id":"Id3aO2mItZ0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cnt = dict()\n","for i,l in enumerate(L):\n","\n","  print(f\"Processing line {i}\")\n","\n","  # get ground truth\n","  idx = n[i]\n","  print(f\"Dataset index {idx}\")\n","  if idx in cnt.keys():\n","    cnt[idx] += 1\n","  else:\n","    cnt[idx]  = 0\n","\n","  truth = ref[idx]\n","\n","  # get DeBERTa containment scores\n","  prompt = f\"[CLS] {truth} [SEP] {r[i]} [SEP]\"\n","  outputs = pipe(prompt)\n","  negF[idx,cnt[idx]] = outputs[0][0]['score']\n","  neuF[idx,cnt[idx]] = outputs[0][1]['score']\n","  entF[idx,cnt[idx]] = outputs[0][2]['score']\n","  prompt = f\"[CLS] {r[i]} [SEP] {truth} [SEP]\"\n","  outputs = pipe(prompt)\n","  negB[idx,cnt[idx]] = outputs[0][0]['score']\n","  neuB[idx,cnt[idx]] = outputs[0][1]['score']\n","  entB[idx,cnt[idx]] = outputs[0][2]['score']\n","\n","  # correct/incorrect/don't know processing\n","  rating = r[i].split(\"\\t\")[-1]\n","  if \"don't know\" in rating.lower():\n","    slf[idx,cnt[idx]] = 0.5\n","  elif \"incorrect\" in rating.lower():\n","    slf[idx,cnt[idx]] = 0\n","  elif \"correct\" in rating.lower():\n","    slf[idx,cnt[idx]] = 1\n","  elif \"don't know\" in r[i].lower():\n","    slf[idx,cnt[idx]] = 0.5\n","  elif \"incorrect\" in r[i].lower():\n","    slf[idx,cnt[idx]] = 0\n","  elif \"correct\" in r[i].lower():\n","    slf[idx,cnt[idx]] = 1\n","  else:\n","    slf[idx,cnt[idx]] = -1"],"metadata":{"id":"X_gsEsO8aMeI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","data = {'entF': entF, 'neuF': neuF, 'negF': negF,\n","        'entB': entB, 'neuB': neuB, 'negB': negB,\n","        'slf': slf}\n","fn_pkl = fn_out.replace(\".txt\", \"-ref.pkl\")\n","with open(fn_pkl, 'wb') as f:\n","    pickle.dump(data, f)"],"metadata":{"id":"yd5QzFeZx7-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Xzy_AvANXxvk"},"execution_count":null,"outputs":[]}]}